{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saranya003/Final_Project/blob/main/Project_2_Item_demand_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLU_B9KTTp92"
      },
      "source": [
        "**Accurate forecasting of demand can help the manufacturers to maintain appropriate stock which results in reduction in loss due to product not being sold and also reduces the opportunity cost (i.e. higher demand but less availability => opportunity lost)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6QP0dZRAe3g"
      },
      "source": [
        "\n",
        "**Data fields**\n",
        "\n",
        "- **date** - Date of the sale data. There are no holiday effects or store closures.\n",
        "- **store** - Store ID\n",
        "- **item** - Item ID\n",
        "- **sales** - Number of items sold at a particular store on a particular date.\n",
        "\n",
        "\n",
        "In this project, the goal is to forecast 3-month sales for 50 different products in 10 different stores when given 5 years of store item sales data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHuXBfr6Alcj"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from time import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8BqG3fuBGYh"
      },
      "outputs": [],
      "source": [
        "# Read the dataset\n",
        "dataset = pd.read_csv(\"item.csv\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJL_jlpnCYWr"
      },
      "source": [
        "### **DATA CLEANING**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qW6I_c7CIeI"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fclIrANbI-L"
      },
      "source": [
        "DATA HAS NO MISSING AND ZERO NULL VALUES FOR ALL COLUMNS SO NO NEED OF IMPUTE AND DROP THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1uEpI0PCm_4"
      },
      "outputs": [],
      "source": [
        "#change the date column datatype object to datetime \n",
        "from datetime import datetime, timedelta, date\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-OyteEXCxuP"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1dZec7EbZar"
      },
      "source": [
        "**Understanding Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK58aba7DN1v",
        "outputId": "2530ecf4-b33c-4d3a-eacb-61644f13512c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date     0\n",
              "store    0\n",
              "item     0\n",
              "sales    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset.isnull().sum() # no null values and no duplicate rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTTqdo71Dcgc"
      },
      "outputs": [],
      "source": [
        "dataset['store'].unique()\n",
        "#dataset.store.unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_GYFYLPEJSe",
        "outputId": "2510b0cd-9bff-4cfa-cfbc-63b550ad1139"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset.store.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3mFAmAIGG-E"
      },
      "outputs": [],
      "source": [
        "dataset.groupby([\"store\"]).agg({\"sales\": [\"count\",\"sum\", \"mean\", \"median\", \"std\", \"min\", \"max\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_n7ORq7EMNP",
        "outputId": "2d07d643-262d-461d-b8dc-369d9853db13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset.item.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W20WS13IEQoV",
        "outputId": "926290a0-295c-4723-8f11-b94749ec28f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset.item.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M6OlNGEGEIz"
      },
      "outputs": [],
      "source": [
        "dataset.groupby([\"item\"]).agg({\"sales\": [\"count\",\"sum\", \"mean\", \"median\", \"std\", \"min\", \"max\"]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74eodD0wc62z"
      },
      "source": [
        "**Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AQ-guTlbt5o"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKwUFsC5hfga",
        "outputId": "8bf2117e-edf4-47b4-fedd-ae8a75592c78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15.5, -4.5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "iqr = dataset['store'].quantile(0.75) - dataset['store'].quantile(0.25)\n",
        "upper_threshold = dataset['store'].quantile(0.75) + (1.5 * iqr)\n",
        "lower_threshold = dataset['store'].quantile(0.25) - (1.5 * iqr)\n",
        "upper_threshold, lower_threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh8TdwAGh6Sn"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "#sns.boxplot(dataset['store'])\n",
        "fig = px.box(dataset[\"store\"])\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS WE OBSERVED THE GRAPH THEIR  IS NO OUTLIERS IN THE STORE\n"
      ],
      "metadata": {
        "id": "uGyvDQpbo30G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hfs_4MAtiHZx",
        "outputId": "f1d684d5-c681-4dc6-c615-955d04e66f9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75.5, -24.5)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "iqr = dataset['item'].quantile(0.75) - dataset['item'].quantile(0.25)\n",
        "upper_threshold = dataset['item'].quantile(0.75) + (1.5 * iqr)\n",
        "lower_threshold = dataset['item'].quantile(0.25) - (1.5 * iqr)\n",
        "upper_threshold, lower_threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A8fj29XiQp0"
      },
      "outputs": [],
      "source": [
        "#sns.boxplot(dataset['item'])\n",
        "fig = px.box(dataset[\"item\"])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSooi-jUcvxq"
      },
      "source": [
        "AS WE OBSERVED THE GRAPH THEIR IS NO OUTLIERS IN THE ITEM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEFyMO24dCrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417b5671-4a4c-4426-fa80-2ca7a02e02a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130.0, -30.0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "iqr = dataset['sales'].quantile(0.75) - dataset['sales'].quantile(0.25)\n",
        "upper_threshold = dataset['sales'].quantile(0.75) + (1.5 * iqr)\n",
        "lower_threshold = dataset['sales'].quantile(0.25) - (1.5 * iqr)\n",
        "upper_threshold, lower_threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIKpcrDzdfZd"
      },
      "outputs": [],
      "source": [
        "fig = px.box(dataset[\"sales\"])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AS WE OBSERVED THE GRAPH THEIR  IS  OUTLIERS IN THE SALES NEED TO CLIP \n",
        "\n"
      ],
      "metadata": {
        "id": "9uQCZUG3p0Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['sales'] = dataset['sales'].clip(upper_threshold,lower_threshold)\n",
        "dataset.sales\n",
        "fig = px.box(dataset[\"sales\"])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "yGn3tNtooNF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AFTER CLIPPING NO OUTLIERS FOUND\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jR5hXohTpncb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "rSuNnyEFqR6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.distplot(dataset['sales'])\n",
        "  \n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(dataset['sales'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7w8pTk_jqhlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4fugOJiBh2j"
      },
      "source": [
        "### **TASK JAR**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.plot(x='item', y='sales', style='o')\n",
        "plt.title('item vs sales')\n",
        "plt.xlabel('item')\n",
        "plt.ylabel('sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LkYS7t2xrUfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.plot(x='store', y='sales', style='o')\n",
        "plt.title('store vs sales')\n",
        "plt.xlabel('store')\n",
        "plt.ylabel('sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bjyvJJUhrXyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.plot(x='date', y='sales', style='o')\n",
        "plt.title('date vs sales')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z8f-gaL6rc-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sales Data Per Item\n",
        "sales_by_item = dataset.groupby('item')['sales'].sum().reset_index()\n",
        "sales_by_item"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Je2N8LBArrVm",
        "outputId": "baf18f2d-73d6-4e3b-ca50-3bc3cdb61a83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e8e80fe3d48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Sales Data Per Item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msales_by_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msales_by_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3XQKp96_IIU"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.barplot(sales_by_item.item, sales_by_item.sales, order=sales_by_item.sort_values('sales', ascending = False).item)\n",
        "#ax.set(xlabel = \"Item Id\", ylabel = \"Sum of Sales\", title = \"Total Sales Per Item\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sales Data Per Store\n",
        "sales_by_store = dataset.groupby('store')['sales'].sum().reset_index()"
      ],
      "metadata": {
        "id": "gTSQg2NXr-5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fvBf_i6HZ3e"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "sns.barplot(sales_by_store.store, sales_by_store.sales, order=sales_by_store.sort_values('sales',ascending = False).store)\n",
        "#ax.set(xlabel = \"Store Id\", ylabel = \"Sum of Sales\", title = \"Total Sales Per Store\")\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "figure(figsize=(18, 4), dpi=80)\n",
        "item_daily = dataset.groupby([\"date\",\"store\"],as_index=False).agg({\"sales\":\"sum\"})\n",
        "\n",
        "item_daily['date'] = pd.to_datetime(item_daily.date, format='%Y/%m/%d')\n",
        "item_1 = item_daily[item_daily['store']==1]\n",
        "ax_2 = sns.scatterplot(data=item_1,x='date',y='sales')\n",
        "ax_2.set_ylabel(\"Sales/store\")"
      ],
      "metadata": {
        "id": "iJYrpcfOsLwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure(figsize=(18, 4), dpi=80)\n",
        "item_daily = dataset.groupby([\"date\",\"item\"],as_index=False).agg({\"sales\":\"sum\"})\n",
        "\n",
        "item_daily['date'] = pd.to_datetime(item_daily.date, format='%Y/%m/%d')\n",
        "item_1 = item_daily[item_daily['item']==1]\n",
        "ax_2 = sns.scatterplot(data=item_1,x='date',y='sales')\n",
        "ax_2.set_ylabel(\"Sales/Item_1\")"
      ],
      "metadata": {
        "id": "WZAa-L0WsVqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri5Pl4UXfZkl"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIQfjZXWINBd"
      },
      "outputs": [],
      "source": [
        "# Convert the date column to a datetime object\n",
        "dataset['date'] = pd.to_datetime(dataset['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nllBMElBC8dF"
      },
      "outputs": [],
      "source": [
        "# Create new columns for year, month, and day\n",
        "dataset['year'] = dataset['date'].dt.year\n",
        "dataset['month'] = dataset['date'].dt.month\n",
        "dataset['day'] = dataset['date'].dt.day"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import calendar\n",
        "      \n",
        "def weekend_or_weekday(year,month,day):\n",
        "      \n",
        "    d = datetime(year,month,day)\n",
        "    if d.weekday()>4:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "  \n",
        "dataset['weekend'] = dataset.apply(lambda x:weekend_or_weekday(x['year'], x['month'], x['day']), axis=1)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "7tpIiAT6rkTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def which_day(year, month, day):\n",
        "      \n",
        "    d = datetime(year,month,day)\n",
        "    return d.weekday()\n",
        "  \n",
        "dataset['weekday'] = dataset.apply(lambda x: which_day(x['year'],x['month'],x['day']),axis=1)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "3e4YDyYVtmXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "import holidays\n",
        "def is_holiday(x):\n",
        "    india_holidays = holidays.country_holidays('IN')\n",
        "    if india_holidays.get(x):\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "dataset['holidays'] = dataset['date'].apply(is_holiday)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "XsSi2lOsxTMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['store', 'year', 'month',\\\n",
        "            'weekday', 'weekend','holidays' ]\n",
        "  \n",
        "plt.subplots(figsize=(20, 10))\n",
        "for i, col in enumerate(features):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    dataset.groupby(col).mean()['sales'].plot.bar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZgHPX7QyyYiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fntTD9DMdp3T"
      },
      "outputs": [],
      "source": [
        "item_i = dataset[dataset['item']==3]\n",
        "item_i"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = item_i.groupby(['date','item'])\n",
        "item_1 = k.agg(sum)\n",
        "item_1=item_1.reset_index()\n",
        "j=[]\n",
        "for i in range(89, len(item_1)):\n",
        "    b = item_1['date'][0+i] # 0 is the starting date and 0+i is the end date\n",
        "    j.append(b)\n",
        "item = item_1.head(1737) # doubt\n",
        "item['end']=j    # doubt\n",
        "date_list = dataset['date'].to_list()\n",
        "d =[]\n",
        "for i in range(1737):\n",
        "     r = item.loc[i, 'end']\n",
        "     a = date_list.index(r)\n",
        "     c =item_1.loc[i:a,'sales'].sum()\n",
        "     d.append(c)\n",
        "item['total'] = d\n",
        "item['date'] = pd.to_datetime(item['date'])\n",
        "item['year'] = item['date'].dt.year\n",
        "item['month'] = item['date'].dt.month\n",
        "item['day'] = item['date'].dt.day"
      ],
      "metadata": {
        "id": "O-cs6dyr1PAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item"
      ],
      "metadata": {
        "id": "ucscoJNI1RDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jacGiFxzO44B"
      },
      "source": [
        "**Split the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cv_FbECsCP8c"
      },
      "outputs": [],
      "source": [
        "x =  item.loc[:,['year','month','day']].values\n",
        "y = item.loc[:,'total'].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIwF8BSsOwH4"
      },
      "source": [
        "***Train and Test the Data***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBc5ZPDGOvJV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size =0.25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDkzxaifeRRG"
      },
      "source": [
        "**Scale the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IJX7OlteSHL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler ## standrard scalig \n",
        "scaler = StandardScaler() #initialise to a variable\n",
        "scaler.fit(x_train) # we are finding the values of mean and sd from the td\n",
        "x_train = scaler.transform(x_train) # fit (mean, sd) and then transform the training data\n",
        "x_test= scaler.transform(x_test) # transform the test data "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MODEL**"
      ],
      "metadata": {
        "id": "Wwi5ttMt1cTM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAvpuXj_FFdW"
      },
      "source": [
        " **Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMGvj-tPCVw_",
        "outputId": "f63ef727-5b9e-4727-9e32-8a68084865fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score for Linear Regression: 0.44510958153315994\n"
          ]
        }
      ],
      "source": [
        "linear =LinearRegression()\n",
        "linear.fit(x_train,y_train)\n",
        "print('score for Linear Regression:',linear.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6wlCV87FR8_"
      },
      "source": [
        "**Decision Tree Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-z6Go-iCeIv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "for depth in [1,2,3,4,5,6,7,8,9,10,20,40,60]:\n",
        "  dt = DecisionTreeRegressor(max_depth=depth)\n",
        "  dt.fit(x_train,y_train)\n",
        "  trainAccuracy = r2_score(y_train,dt.predict(x_train))\n",
        "  dt = DecisionTreeRegressor(max_depth = depth)\n",
        "  valAccuracy = cross_val_score(dt, x_train, y_train, cv=10, scoring = make_scorer(r2_score))\n",
        "  print(\"Depth:\",depth,'Train R2:',trainAccuracy,'Val Score:',np.mean(valAccuracy))\n",
        "dt = DecisionTreeRegressor(max_depth = int(input('max depth value')))\n",
        "dt.fit(x_train,y_train)\n",
        "#print('score for Decision Treeregressor:',dt.score(x_test,y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk5HureNFZHw"
      },
      "source": [
        "**KNeighborsRegressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGRINHkcD08j"
      },
      "outputs": [],
      "source": [
        "#from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "for i in [1,2,3,4,5,6,7,8,9,10,20,50]:\n",
        "  knn = KNeighborsRegressor(i)\n",
        "  knn.fit(x_train,y_train)\n",
        "  print('k value:',i ,'train score:',knn.score(x_train,y_train),'cv score:',np.mean(cross_val_score(knn, x_train, y_train, cv=10, scoring = make_scorer(r2_score))))\n",
        "knn =KNeighborsRegressor(int(input('enter k values:')))\n",
        "knn.fit(x_train,y_train)\n",
        "#print('score for knn regression :',knn.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UmJDzooH08B",
        "outputId": "3106321a-1bba-4733-944c-e7d21dafa931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.2.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBRegressor**"
      ],
      "metadata": {
        "id": "D76gEP8XzES0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "for lr in [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.2,0.5,0.7,1]:\n",
        "  model = xgb.XGBRegressor(learning_rate = lr,n_estimators =100,verbosity =0)#initialise the model\n",
        "  model.fit(x_train,y_train)\n",
        "  model.score(x_test,y_test)\n",
        "  print('Learning rate:',lr,\"Train score\",model.score(x_train,y_train),'Cross-Val score:',np.mean(cross_val_score(model,x_train,y_train,cv=10)))\n",
        "model = xgb.XGBRegressor(learning_rate = float(input('LR value')),n_estimators =100) \n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "print('score for the XGBRegressor:',model.score(x_test,y_test))"
      ],
      "metadata": {
        "id": "c65pjPvhzBZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy**"
      ],
      "metadata": {
        "id": "A_qKcNdP2iF5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v18g4qzbHedR",
        "outputId": "1686b94a-af97-4c76-9f23-6dfe12809d33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for the Linear Regressor       : 0.44510958153315994\n",
            "Score for the Decision TreeRegressor : 0.9845198675189734\n",
            "Score for the KNN Regressor          : 0.9738434304408886\n",
            "Score for the XGBRegressor           : 0.9988394789713089\n"
          ]
        }
      ],
      "source": [
        "print('Score for the Linear Regressor       :',linear.score(x_test,y_test))    \n",
        "print('Score for the Decision TreeRegressor :',dt.score(x_test,y_test))    \n",
        "print('Score for the KNN Regressor          :',knn.score(x_test,y_test)) \n",
        "print('Score for the XGBRegressor           :',model.score(x_test,y_test))  \n",
        "#print('score for the Random Forest:',RF.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_pred = linear.predict(x_test)\n",
        "dt_pred= dt.predict(x_test)\n",
        "knn_pred=knn.predict(x_test)\n",
        "xgb_pred=model.predict(x_test)"
      ],
      "metadata": {
        "id": "kMQN93fozoZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpW7dFdBdQS7"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"Actual\":y_test, \"linear_pred\":linear_pred,\"dt_pred\":dt_pred, \"knn_pred\":knn_pred,\"xgb_pred\":xgb_pred })"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCFfC5WmbyOubxV4+0QYfR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}